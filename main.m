%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%         MAIN SCRIPT FOR TRAINING AN AGENT TO INTERCEPT A TARGET         %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% This script details how to loads auxiliary functions associated with the
% primary learning algorithm. It uses these and other functions to load
% pre-stored parameters values and build data structures that specify the
% properties of the spatial environment, training protocol, and agent.
%
% As specified below, the follow data structures must be constructed before
% running the learning algorithm: 
%       arena:      properties of the spatial environment
%       belief:     properties of the agent's belief about the environment
%       sampler:    properties that specify how the agent samples new anchor
%                       points to guide trajectories through the environment
%       planner:    properties that specity how the agent plans a trajectory 
%                       through the set of sampled anchor points    
%       trial:      properties that specify the training protocol, including
%                       target and obstacle locations
% 
% Once the data structures above have been constructed, a single agent can
% be generated by running:
%       simResults = runSingleAgent(arena,belief,sampler,planner,trial);
%
% The output structure 'simResults' contains the results from the training
% protocol, including beliefs, planned and executed trajectories, and 
% outcomes of executed trajectories.
%
% For more info on any of the functions in the repo, run:
%       help myfunction


%% load auxiliary and plotting functions

addpath("auxiliaryFunctions/","auxiliaryFunctions/peaks2/",...
    "plottingFunctions/","sims/","plottingFunctions/aux/");


%% load plotting parameters

plotType = 'whiteBG';                                                       % current options: 'whiteBG'
plotParams = loadPlotParams(plotType);

%% generate basic structures for environment, trial protocol, and agent

[arena,belief,sampler,planner,trial] = loadExperiment('singleTarget');      % current trial type options: 'singleTarget', 'multiTarget', 'obstacle'

%% simulate a single agent and plot results from a single trial

simResults = runSingleAgent(belief,sampler,planner,trial);

trialID = 2;
plotSingleTrial(agent.simResults,agent.belief,agent.trial,trialID,plotParams);


%% simulate many agents, store results, and plot results averaged across agents

nAgents = 50;
multiAgentResults = runMultipleAgents(nAgents,belief,sampler,planner,trial);
plotMultipleTargets(multiAgentResults,trial,agentParams,plotParams);


%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                        GENERATE MANUSCRIPT FIGURES                      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%                         FIGURE 2: SINGLE TARGET                       %%

%--------------- run single agent, illustrate results --------------------%
% parameter settings
% exptType = 'singleTarget'
% agentParams.resetFlag = false;
% agentParams.cacheFlag = false; 

% to run from scratch
% simResults = runSingleAgent(belief,sampler,planner,trial);

load('sims/singleAgent_oneTarget_2-12-2025.mat')
trialID = 2;

% FIG 2E: schematic of trajectory planner 
plotSchematic_trajectoryPlanning(simResults,arena,belief,sampler,planner,trial,trialID,plotParams)

% FIG 2F: schematic of belief update
plotSchematic_beliefUpdate(simResults,arena,belief,sampler,planner,trial,trialID,plotParams)

% FIG 2G: schematic of anchor sampling
plotSchematic_anchorSampling(simResults,arena,belief,sampler,planner,trialID,plotParams);

% Fig 2I: consolidation of belief over time within a single agent
plotSchematic_beliefConsolidation(res,arena,belief,sampler,planner,trial,plotParams)


%--------- run multiple agents, illustrate trial-averaged results --------%
% to run from scratch
% nAgents = 200;
% multiAgentResults = runMultipleAgents(nAgents,belief,sampler,planner,trial);

load('sims/multiAgent_oneTarget_2-12-2025.mat')

% Fig 2H: average performance on single target
plotResults_avgPerformance(multiAgentResults,trial,agentParams,plotParams)


%%                      FIGURE 3: MULTIPLE TARGETS                       %%
%----- run multiple agents on 5 targets, plot trial-averaged results -----%
% parameter settings
% exptType = 'multiTarget';
% trialParams.nBlocks   = 2;
% agentParams.resetFlag = false; % set 1
% agentParams.resetFlag = true;  % set 2
% agentParams.cacheFlag = false; 

% to run from scratch (reset parameters between each run):
% nAgents = 200;
% multiAgentResults1 = runMultipleAgents(nAgents,belief,sampler,planner,trial);   %(agentParams.resetFlag = false)
% multiAgentResults2 = runMultipleAgents(nAgents,belief,sampler,planner,trial);   %(agentParams.resetFlag = true)

multiAgentResults1 = load('sims/multiAgent_twoTarget_nosurpriseReset_2-12-2025.mat');
multiAgentResults1 = multiAgentResults1.multiAgentResults;
multiAgentResults2 = load('sims/multiAgent_twoTarget_surpriseReset_2-12-2025.mat'); 
multiAgentResults2 = multiAgentResults2.multiAgentResults;

% Fig 3A: compare average performance with and without target switch
plotResults_surpriseReset(multiAgentResults1,multiAgentResults2,trial,agentParams,plotParams)

%----- run multiple agents on 5 targets, plot trial-averaged results -----%
% parameter settings
% exptType = 'multiTarget';
% trialParams.nBlocks   = 5;
% agentParams.resetFlag = true;
% agentParams.cacheFlag = false; 

% to run from scratch
% nAgents = 200;
% multiAgentResults = runMultipleAgents(nAgents,belief,sampler,planner,trial);

load('sims/multiAgent_oneTarget_2-12-2025.mat')

% Fig 3B: average performance and speed of learning
plotResults_avgPerformance(multiAgentResults,trial,agentParams,plotParams)

%%                          FIGURE 4: CACHING                            %%
%----- run multiple agents on 5 targets, plot trial-averaged results -----%
% parameter settings
% exptType = 'multiTarget';
% trialParams.nBlocks   = 5;
% agentParams.resetFlag = true; 
% agentParams.cacheFlag = true; 

% to run from scratch:
% nAgents = 200;
% multiAgentResults = runMultipleAgents(nAgents,belief,sampler,planner,trial);  

plotResults_avgPerformance(multiAgentResults,trial,agentParams,plotParams)
plotResults_initAnchorAngles(res,trial,plotParams)


%%                     FIGURE 5: OBSTACLE AVOIDANCE                      %%
%----------------- illustrate construction of errormap -------------------%

plotSchematic_obstacleAvoidance(arena,belief,planner,trial,plotParams)


%-- run multiple agents on target/obstacle, plot trial-averaged results --%
% parameter settings
% exptType = 'obstacle';
% agentParams.resetFlag = true;
% agentParams.cacheFlag = false; 

% to run from scratch (reset parameters between each run):
% nAgents = 200;
% multiAgentResults = runMultipleAgents(nAgents,belief,sampler,planner,trial);   


load('sims/multiAgent_obstacle_2-13-2025.mat')

% Fig 5B: average performance and speed of learning with obstacle
plotResults_avgPerformance(multiAgentResults,trial,agentParams,plotParams)