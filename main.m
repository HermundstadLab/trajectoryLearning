%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%         MAIN SCRIPT FOR TRAINING AN AGENT TO INTERCEPT A TARGET         %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% This script details how to generate environment, agent, and trial 
% structures associated with the primary learning algorithm. It also
% contains plotting functions for all of the figures in the manuscript.
%
% As specified below, the follow data structures must be constructed before
% running the learning algorithm: 
%       environment:    properties of the spatial environment
%       agent:          properties of the agent
%                       agent.belief:     properties of the agent's belief 
%                                           about the environment
%                       agent.sampler:    properties that specify how the 
%                                           agent samples new anchor points
%                                           to guide trajectories through 
%                                           the environment
%                       agent.planner:    properties that specity how the 
%                                           agent plans a trajectory
%                                           through the set of sampled 
%                                           anchor points    
%       trial:          properties that specify the training protocol, 
%                           including target and obstacle locations
%
% Once the data structures above have been constructed, a single agent can
% be generated by running:
%       simResults = runSingleAgent(agent,trial)
%
% The output structure 'simResults' contains the results from the training
% protocol, including beliefs, planned and executed trajectories, and 
% outcomes of executed trajectories.
%
% For more info on any of the functions in the repo, run:
%       help myfunction


%% load auxiliary and plotting functions

addpath("auxiliaryFunctions/","auxiliaryFunctions/peaks2/",...
    "plottingFunctions/","sims/","plottingFunctions/aux/");


%% load plotting parameters

plotType = 'whiteBG';                                                               
plotParams = loadPlotParams(plotType);

%% generate basic structures for environment, agent, and trial protocol 

[agent,environment] = generateEnvironment('default');
agent               = generateAgent(agent,'default');
trial               = generateTrialStructure(environment,'singleTarget');

%% simulate a single agent and plot results from a single trial

singleAgentResults = runSingleAgent(agent,trial);

trialID = 3;
plotSingleAgentResults_singleTrialEvolution(singleAgentResults,environment,agent,trial,trialID,plotParams);


%% simulate many agents, store results, and plot results averaged across agents

nAgents = 5;
multiAgentResults = runMultipleAgents(nAgents,agent,trial);
plotMultiAgentResults_avgPerformance(multiAgentResults,agent,trial,plotParams);


%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                        GENERATE MANUSCRIPT FIGURES                      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% use same default environment for all simulations
[agent,environment] = generateEnvironment('default');

%%                    FIGURE 2: ILLUSTRATE ALGORITHM                     %%

%--------------- run single agent, illustrate results --------------------%
agent = generateAgent(agent,'default','resetFlag',false,'cacheFlag',false);
trial = generateTrialStructure(environment,'singleTarget');
singleAgentResults = runSingleAgent(agent,trial);

trialID = 2;

% FIG 2E: schematic of trajectory planner 
plotSchematic_planTrajectory(singleAgentResults,environment,agent,trial,trialID,plotParams);

% FIG 2F: schematic of belief update
plotSchematic_updateBelief(singleAgentResults,environment,agent,trial,trialID,plotParams);

% FIG 2G: schematic of anchor sampling
plotSchematic_sampleAnchors(singleAgentResults,arena,belief,sampler,planner,trialID,plotParams);


%%                      FIGURE 3: SINGLE TARGET                          %%

%-------------- run multiple agents, illustrate results ------------------%
agent = generateAgent(agent,'default','resetFlag',false,'cacheFlag',false);
trial = generateTrialStructure(environment,'singleTarget');


% Fig 3A: average learning results for single target 
nAgents = 200;
multiAgentResults = runMultipleAgents(nAgents,agent,trial);
plotMultiAgentResults_avgPerformance(multiAgentResults,agent,trial,plotParams);

% Fig 3B: consolidation of belief over time within a single agent
singleAgentResults = runSingleAgent(agent,trial);
plotSingleAgentResults_targetBeliefEvolution(singleAgentResults,environment,agent,trial,plotParams);

% Fig 3D: immediate generalization to new entrances
trial = generateTrialStructure(environment,'new entry','nBlocks',4,'nTrialsPerBlock',20);
singleAgentResults = runSingleAgent(agent,trial);
trialIDs = [20,40,60,80];
plotSingleAgentResults_trajectories(singleAgentResults,environment,agent,trial,trialIDs,plotParams)


%%                      FIGURE 4: MULTIPLE TARGETS                       %%

%------- run agents on 2 targets, with and without surprise reset --------%

agent1 = generateAgent(agent,'default','resetFlag',false,'cacheFlag',false);
agent2 = generateAgent(agent,'default','resetFlag',true,'cacheFlag',false);
trial  = generateTrialStructure(environment,'multiTarget','nBlocks',2);

nAgents = 5;
multiAgentResults1 = runMultipleAgents(nAgents,agent1,trial);  
multiAgentResults2 = runMultipleAgents(nAgents,agent2,trial);   

% Fig 4A: compare average performance with and without target switch
plotMultiAgentResults_surpriseReset(multiAgentResults1,multiAgentResults2,agent,trial,plotParams);


%-------------- run agents on 5 targets with surprise reset --------------%
nAgents = 5;
trial  = generateTrialStructure(environment,'multiTarget','nBlocks',5);
multiAgentResults = runMultipleAgents(nAgents,agent2,trial);

% Fig 4B: average performance and speed of learning
plotMultiAgentResults_avgPerformance(multiAgentResults,agent,trial,plotParams);


%%                          FIGURE 5: CACHING                            %%

%--------------- run single agent on 5 targets with caching --------------%

agent = generateAgent(agent,'default','resetFlag',true,'cacheFlag',true);
trial  = generateTrialStructure(environment,'multiTarget','nBlocks',5);

% Fig 5C-D: angle to first anchor point and context posterior over time
singleAgentResults = runSingleAgent(agent,trial);
plotSingleAgentResults_contextBeliefEvolution(singleAgentResults,trial,plotParams)


%%                     FIGURE 6: OBSTACLE AVOIDANCE                      %%

%-------------- illustrate construction & use of errormap ----------------%
agent = generateAgent(agent,'default','resetFlag',true,'cacheFlag',false);
trial  = generateTrialStructure(environment,'obstacle');

singleAgentResults = runSingleAgent(agent,trial);

% Fig 6A: illustrate construction of errormap
plotSchematic_constructErrormap(environment,agent,trial,plotParams);

% Fig 6B: illustrate use of errormap
trialID = 10;
plotSchematic_augmentAnchors(singleAgentResults,environment,agent,trial,trialID,plotParams)

% Fig 6C: illustrate co-evolution of belief and errormap
plotSingleAgentResults_targetBeliefEvolution(singleAgentResults,environment,agent,trial,plotParams)


%------ run multiple agents obstacle, plot trial-averaged results --------%
nAgents = 5;
multiAgentResults = runMultipleAgents(nAgents,agent,trial);

% Fig 6D: average performance when obstacle introduced from first trial
plotMultiAgentResults_avgPerformance(multiAgentResults,agent,trial,plotParams);

% Fig 6E: average performance when obstacle introduced after learning
trial  = generateTrialStructure(environment,'interleaved obstacle');
multiAgentResults = runMultipleAgents(nAgents,agent,trial);

plotMultiAgentResults_avgPerformance(multiAgentResults,agent,trial,plotParams);

